{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b76541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "It has an extensive choice of tools and libraries that support Computer Vision, Natural Language Processing(NLP), and \n",
    "many more ML programs. recognize the relationship between words)\n",
    "Python program using PyTorch for defining tensors fit a two-layer network to random data and calculating the loss.\n",
    "\"\"\"\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2f069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], requires_grad=True)\n",
      "torch.float32\n",
      "cpu\n",
      "torch.Size([2, 3])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "##initializing Tensor\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "my_tensor = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "print(my_tensor)\n",
    "print(my_tensor.dtype)\n",
    "print(my_tensor.device)\n",
    "print(my_tensor.shape)\n",
    "print(my_tensor.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046f06e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6df2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Other common initialization methods\n",
    "x1= torch.empty(size=(3,3))\n",
    "\"\"\"\n",
    "tensor([[0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.]])\n",
    "\"\"\"\n",
    "\n",
    "x2= torch.zeros((3,3))\n",
    "\"\"\"\n",
    "tensor([[0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.]])\n",
    "\"\"\"\n",
    "\n",
    "x3= torch.rand((3,3))\n",
    "\"\"\"\n",
    "tensor([[0.8156, 0.5082, 0.8837],\n",
    "        [0.5388, 0.7806, 0.6653],\n",
    "        [0.3834, 0.2005, 0.6963]])\n",
    "\"\"\"\n",
    "\n",
    "x4= torch.ones((3,3))\n",
    "\"\"\"\n",
    "tensor([[1., 1., 1.],\n",
    "        [1., 1., 1.],\n",
    "        [1., 1., 1.]])\n",
    "\"\"\"\n",
    "\n",
    "x5= torch.eye(3,3)\n",
    "\"\"\"\n",
    "tensor([[1., 0., 0.],\n",
    "        [0., 1., 0.],\n",
    "        [0., 0., 1.]])\n",
    "\"\"\"\n",
    "\n",
    "x6= torch.arange(start=0, end=5, step=1)\n",
    "\"\"\"\n",
    "tensor([0, 1, 2, 3, 4])\n",
    "\"\"\"\n",
    "\n",
    "x7= torch.linspace(start=0.1, end=2, steps=9)\n",
    "\"\"\"\n",
    "tensor([0.1000, 0.3375, 0.5750, 0.8125, 1.0500, 1.2875, 1.5250, 1.7625, 2.0000])\n",
    "\"\"\"\n",
    "\n",
    "x8= torch.empty(size=(1,5)).normal_(mean=0, std=1)\n",
    "\"\"\"\n",
    "tensor([[ 0.3494,  0.3771,  0.8429,  0.4100, -0.0471]])\n",
    "\"\"\"\n",
    "\n",
    "x9= torch.empty(size=(1,5)).uniform_(0,1)\n",
    "\"\"\"\n",
    "tensor([[0.3921, 0.1638, 0.1746, 0.2933, 0.2344]])\n",
    "\"\"\"\n",
    "\n",
    "x10= torch.diag(torch.ones(3))\n",
    "\"\"\"\n",
    "torch.diag() is a function that constructs a diagonal matrix from the given input tensor. \n",
    "tensor([[1., 0., 0.],\n",
    "        [0., 1., 0.],\n",
    "        [0., 0., 1.]])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(x10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3bea157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "tensor([False,  True,  True,  True])\n",
      "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#how to initialize and convert tensors to other types (int, float, double)\n",
    "tensor = torch.arange(4)\n",
    "print(tensor)\n",
    "print(tensor.bool()) #boolean True/False\n",
    "print(tensor.short()) #int16\n",
    "print(tensor.long()) #int64 (important)\n",
    "print(tensor.half()) #float16\n",
    "print(tensor.float()) #float32 (important)\n",
    "print(tensor.double()) #float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecfea82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Array to tensor Conversion and vice-versa\n",
    "import numpy as np\n",
    "np_array = np.zeros((5,5))\n",
    "print(np_array)\n",
    "tensor = torch.from_numpy(np_array)\n",
    "print(tensor)\n",
    "np_array_back = tensor.numpy()\n",
    "print(np_array_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fbe3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 10., 10.])\n",
      "tensor([10, 10, 10])\n",
      "tensor([10, 10, 10])\n",
      "-----------------------------\n",
      "tensor([0., 0., 0.])\n",
      "tensor([1., 2., 3.])\n",
      "tensor([2., 4., 6.])\n",
      "-----------------------------\n",
      "tensor([1, 4, 9])\n",
      "-----------------------------\n",
      "tensor([True, True, True])\n",
      "-----------------------------\n",
      "tensor([[0.9959, 0.9109, 1.0262],\n",
      "        [2.0167, 1.2918, 1.4539]])\n",
      "tensor([[0.9959, 0.9109, 1.0262],\n",
      "        [2.0167, 1.2918, 1.4539]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "-----------------------------\n",
      "tensor([[1.9478, 1.6075, 2.4810, 2.9699, 1.0305],\n",
      "        [2.7007, 2.1354, 3.3142, 3.7972, 1.3692],\n",
      "        [3.3149, 2.6221, 4.0909, 4.5908, 1.5071],\n",
      "        [2.6780, 2.1617, 3.3195, 3.8272, 1.4424],\n",
      "        [2.1022, 1.6157, 2.3755, 2.9176, 1.1901]])\n",
      "-----------------------------\n",
      "tensor([ 9, 16, 21])\n",
      "-----------------------------\n",
      "tensor(46)\n",
      "-----------------------------\n",
      "tensor([[[5.1267, 5.2782, 4.1132,  ..., 3.2881, 4.9251, 5.2957],\n",
      "         [6.2456, 5.5825, 4.8629,  ..., 4.3716, 6.1909, 5.7134],\n",
      "         [4.9492, 4.9385, 4.0912,  ..., 3.9095, 5.4050, 4.7191],\n",
      "         ...,\n",
      "         [4.8395, 4.9612, 4.2122,  ..., 4.2124, 5.6546, 4.5952],\n",
      "         [4.5952, 4.9589, 3.5175,  ..., 2.9810, 4.5433, 4.8767],\n",
      "         [5.5688, 6.1644, 4.6392,  ..., 4.5920, 6.3354, 4.7569]],\n",
      "\n",
      "        [[5.0530, 6.0068, 3.9815,  ..., 4.0190, 6.4544, 3.9367],\n",
      "         [4.9443, 6.3245, 5.0332,  ..., 4.4406, 7.2124, 3.9178],\n",
      "         [4.4378, 5.1157, 3.5806,  ..., 4.0689, 6.2599, 3.1472],\n",
      "         ...,\n",
      "         [5.3605, 5.9677, 4.5101,  ..., 3.5317, 6.6505, 4.1511],\n",
      "         [4.1587, 4.9373, 4.3959,  ..., 4.7622, 5.5779, 3.3344],\n",
      "         [3.9944, 3.7641, 4.2654,  ..., 3.6544, 5.1919, 3.2149]],\n",
      "\n",
      "        [[6.3179, 6.8345, 6.2246,  ..., 5.1831, 6.5665, 6.7179],\n",
      "         [4.6430, 5.0237, 4.3209,  ..., 2.9397, 4.3641, 4.7660],\n",
      "         [5.1293, 4.7380, 4.5191,  ..., 4.6336, 4.8327, 5.0996],\n",
      "         ...,\n",
      "         [4.4674, 4.6175, 3.7196,  ..., 3.7486, 3.9134, 3.7766],\n",
      "         [4.7463, 5.2510, 4.6845,  ..., 3.8301, 5.3948, 4.1941],\n",
      "         [7.0367, 6.5683, 5.5850,  ..., 5.3208, 6.7009, 6.4615]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[6.7642, 6.4678, 6.2209,  ..., 5.9380, 6.8121, 5.8572],\n",
      "         [4.7432, 3.6878, 4.2019,  ..., 5.0465, 4.8003, 4.0631],\n",
      "         [5.1209, 5.0102, 4.4903,  ..., 5.2597, 5.2034, 4.6892],\n",
      "         ...,\n",
      "         [5.9732, 5.1679, 5.2365,  ..., 6.0216, 4.9974, 4.6569],\n",
      "         [4.8501, 4.8940, 4.4214,  ..., 4.6359, 4.7580, 4.4772],\n",
      "         [5.0404, 4.4858, 4.8903,  ..., 4.9585, 5.2562, 4.2318]],\n",
      "\n",
      "        [[4.9189, 5.0582, 4.7162,  ..., 6.1036, 4.1694, 4.9919],\n",
      "         [4.0199, 3.6592, 3.2034,  ..., 4.9174, 3.7801, 4.4217],\n",
      "         [5.8182, 5.5827, 3.9681,  ..., 6.3676, 5.4832, 5.6847],\n",
      "         ...,\n",
      "         [5.8247, 5.3585, 4.8163,  ..., 6.9885, 5.9168, 6.7251],\n",
      "         [3.8241, 3.8487, 4.1341,  ..., 5.3221, 4.4056, 4.3479],\n",
      "         [4.2206, 4.3951, 4.5561,  ..., 5.3571, 4.8298, 5.0663]],\n",
      "\n",
      "        [[4.3730, 4.9661, 3.5763,  ..., 3.7818, 4.4657, 4.8605],\n",
      "         [6.5888, 7.3771, 5.2863,  ..., 6.2322, 6.6726, 6.9219],\n",
      "         [5.8039, 6.1775, 3.7424,  ..., 5.4451, 5.3829, 6.5102],\n",
      "         ...,\n",
      "         [4.8261, 5.6751, 3.7264,  ..., 4.8372, 4.9518, 5.9247],\n",
      "         [5.6353, 6.2988, 4.6682,  ..., 4.7030, 5.5121, 6.5092],\n",
      "         [5.2825, 5.3383, 3.8360,  ..., 4.7629, 5.1908, 5.3837]]])\n"
     ]
    }
   ],
   "source": [
    "#Tensor Math & Comparison Operations\n",
    "x = torch.tensor([1,2,3])\n",
    "y=torch.tensor([9,8,7])\n",
    "\n",
    "#Addition\n",
    "z1=torch.empty(3)\n",
    "torch.add(x,y,out=z1)\n",
    "print(z1)\n",
    "\n",
    "z2=torch.add(x,y)\n",
    "print(z2)\n",
    "\n",
    "z=x+y\n",
    "print(z)\n",
    "\n",
    "#Subtraction\n",
    "z=x-y\n",
    "\n",
    "#Division\n",
    "z = torch.true_divide(x,y)\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "#inplace operations\n",
    "t1=torch.zeros(3)\n",
    "print(t1)\n",
    "t1.add_(x)\n",
    "print(t1)\n",
    "t1+=x #t=t+x\n",
    "print(t1)\n",
    "\"\"\"\n",
    "tensor([0., 0., 0.])\n",
    "tensor([1., 2., 3.])\n",
    "tensor([2., 4., 6.])\n",
    "\"\"\"\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "#Exponentiation\n",
    "z=x.pow(2)\n",
    "print(z) #z=x^2\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "#simple comparison\n",
    "z1 = x>0\n",
    "z2 = x<0\n",
    "print(z1)\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "#Matrix Multiplication\n",
    "x1=torch.rand((2,5))\n",
    "x2=torch.rand((5,3))\n",
    "x3=torch.mm(x1,x2)\n",
    "x4=x1.mm(x2)\n",
    "print(x3)\n",
    "print(x4)\n",
    "print(x3==x4)\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "#matrix exponentiation\n",
    "matrix_exp = torch.rand(5,5)\n",
    "print(matrix_exp.matrix_power(3))\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "#element wise mult.\n",
    "z=x*y\n",
    "print(z)\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "# dot product\n",
    "z = torch.dot(x,y)\n",
    "print(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e202eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "tensor([[[0.3261, 0.5416, 0.0033,  ..., 0.5979, 0.6389, 0.2050],\n",
      "         [0.9403, 0.6956, 0.9694,  ..., 0.3629, 0.0413, 0.2487],\n",
      "         [0.3871, 0.8399, 0.9203,  ..., 0.8308, 0.1271, 0.2599],\n",
      "         ...,\n",
      "         [0.1571, 0.1961, 0.0178,  ..., 0.9205, 0.5608, 0.0213],\n",
      "         [0.7967, 0.6786, 0.0385,  ..., 0.1448, 0.1678, 0.7287],\n",
      "         [0.1140, 0.8678, 0.3164,  ..., 0.3878, 0.9285, 0.0601]],\n",
      "\n",
      "        [[0.1427, 0.9159, 0.1636,  ..., 0.9238, 0.3848, 0.9162],\n",
      "         [0.0821, 0.8183, 0.8511,  ..., 0.1967, 0.1390, 0.7022],\n",
      "         [0.7436, 0.5789, 0.1006,  ..., 0.6331, 0.1099, 0.8979],\n",
      "         ...,\n",
      "         [0.2077, 0.6014, 0.9732,  ..., 0.0348, 0.7231, 0.6928],\n",
      "         [0.0643, 0.4632, 0.6202,  ..., 0.4576, 0.5869, 0.9446],\n",
      "         [0.1000, 0.5531, 0.0219,  ..., 0.9096, 0.4271, 0.3963]],\n",
      "\n",
      "        [[0.7026, 0.5764, 0.8544,  ..., 0.8111, 0.6709, 0.0223],\n",
      "         [0.7748, 0.5295, 0.8228,  ..., 0.8272, 0.7359, 0.5820],\n",
      "         [0.8686, 0.3025, 0.3040,  ..., 0.7455, 0.8665, 0.7565],\n",
      "         ...,\n",
      "         [0.4965, 0.1614, 0.9989,  ..., 0.3720, 0.3590, 0.7849],\n",
      "         [0.1227, 0.1196, 0.1279,  ..., 0.1699, 0.2822, 0.7180],\n",
      "         [0.9632, 0.0720, 0.8768,  ..., 0.1943, 0.2905, 0.1293]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.8379, 0.0498, 0.0370,  ..., 0.9300, 0.8750, 0.5992],\n",
      "         [0.5234, 0.6678, 0.1285,  ..., 0.7620, 0.2015, 0.8376],\n",
      "         [0.4763, 0.0919, 0.4796,  ..., 0.5495, 0.7512, 0.8763],\n",
      "         ...,\n",
      "         [0.9011, 0.6666, 0.9788,  ..., 0.3911, 0.1676, 0.7643],\n",
      "         [0.1690, 0.0420, 0.5575,  ..., 0.3170, 0.1852, 0.8541],\n",
      "         [0.0829, 0.4334, 0.7306,  ..., 0.9293, 0.4064, 0.9276]],\n",
      "\n",
      "        [[0.7929, 0.2037, 0.5722,  ..., 0.1907, 0.7470, 0.8362],\n",
      "         [0.5064, 0.1374, 0.2574,  ..., 0.7841, 0.9310, 0.2622],\n",
      "         [0.0364, 0.5094, 0.3660,  ..., 0.4657, 0.9095, 0.0886],\n",
      "         ...,\n",
      "         [0.9610, 0.5558, 0.5940,  ..., 0.2075, 0.8812, 0.8743],\n",
      "         [0.1594, 0.4782, 0.3963,  ..., 0.2258, 0.5884, 0.5703],\n",
      "         [0.2216, 0.2441, 0.1039,  ..., 0.6698, 0.8595, 0.6391]],\n",
      "\n",
      "        [[0.0209, 0.0039, 0.4468,  ..., 0.5817, 0.4133, 0.4639],\n",
      "         [0.7389, 0.3373, 0.1881,  ..., 0.1237, 0.6215, 0.3221],\n",
      "         [0.4604, 0.9305, 0.9290,  ..., 0.9944, 0.2439, 0.0344],\n",
      "         ...,\n",
      "         [0.3705, 0.0205, 0.7552,  ..., 0.6546, 0.0546, 0.1460],\n",
      "         [0.9884, 0.4737, 0.0851,  ..., 0.3544, 0.0496, 0.7592],\n",
      "         [0.6232, 0.1038, 0.6436,  ..., 0.3733, 0.6514, 0.0792]]])\n",
      "tensor([[[0.1191, 0.9905, 0.8258,  ..., 0.6771, 0.8739, 0.4703],\n",
      "         [0.9325, 0.7986, 0.0192,  ..., 0.8364, 0.1740, 0.1024],\n",
      "         [0.8546, 0.6933, 0.5643,  ..., 0.1979, 0.4884, 0.2242],\n",
      "         ...,\n",
      "         [0.7367, 0.0542, 0.3306,  ..., 0.5898, 0.1925, 0.2461],\n",
      "         [0.8624, 0.9574, 0.7214,  ..., 0.7098, 0.0313, 0.2871],\n",
      "         [0.4159, 0.6435, 0.9729,  ..., 0.4031, 0.7228, 0.9361]],\n",
      "\n",
      "        [[0.0613, 0.5193, 0.2169,  ..., 0.9251, 0.2837, 0.3849],\n",
      "         [0.8736, 0.3719, 0.1343,  ..., 0.4286, 0.5939, 0.6275],\n",
      "         [0.6511, 0.6534, 0.2694,  ..., 0.0096, 0.3383, 0.3349],\n",
      "         ...,\n",
      "         [0.8789, 0.8454, 0.8543,  ..., 0.9022, 0.2404, 0.1612],\n",
      "         [0.0124, 0.2445, 0.0417,  ..., 0.1554, 0.8439, 0.8905],\n",
      "         [0.5295, 0.7956, 0.6778,  ..., 0.4660, 0.8221, 0.8393]],\n",
      "\n",
      "        [[0.7370, 0.5330, 0.7977,  ..., 0.1833, 0.5553, 0.5544],\n",
      "         [0.3161, 0.4383, 0.7473,  ..., 0.1463, 0.9007, 0.4328],\n",
      "         [0.2704, 0.0127, 0.3273,  ..., 0.3019, 0.7890, 0.4520],\n",
      "         ...,\n",
      "         [0.4579, 0.5342, 0.3880,  ..., 0.8238, 0.1394, 0.8959],\n",
      "         [0.6481, 0.3011, 0.3879,  ..., 0.4417, 0.3332, 0.3420],\n",
      "         [0.8008, 0.5558, 0.4798,  ..., 0.1698, 0.6423, 0.8539]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5388, 0.4591, 0.5443,  ..., 0.1440, 0.6785, 0.6609],\n",
      "         [0.3888, 0.6639, 0.8014,  ..., 0.2410, 0.5153, 0.4732],\n",
      "         [0.9885, 0.8858, 0.2880,  ..., 0.2857, 0.3825, 0.3094],\n",
      "         ...,\n",
      "         [0.2825, 0.2999, 0.1246,  ..., 0.8030, 0.8397, 0.6871],\n",
      "         [0.3998, 0.2525, 0.0047,  ..., 0.9114, 0.3592, 0.7372],\n",
      "         [0.5409, 0.9440, 0.7462,  ..., 0.3332, 0.6189, 0.3705]],\n",
      "\n",
      "        [[0.6562, 0.6170, 0.7973,  ..., 0.2940, 0.9388, 0.3183],\n",
      "         [0.6570, 0.0998, 0.0275,  ..., 0.9875, 0.3595, 0.6252],\n",
      "         [0.7782, 0.9035, 0.2688,  ..., 0.5840, 0.1321, 0.1177],\n",
      "         ...,\n",
      "         [0.0598, 0.5381, 0.2919,  ..., 0.0110, 0.8356, 0.1605],\n",
      "         [0.5782, 0.5068, 0.4366,  ..., 0.9439, 0.4726, 0.0772],\n",
      "         [0.1099, 0.8981, 0.5455,  ..., 0.6945, 0.1964, 0.9552]],\n",
      "\n",
      "        [[0.8566, 0.7437, 0.3224,  ..., 0.9755, 0.8971, 0.2491],\n",
      "         [0.3678, 0.8233, 0.8341,  ..., 0.8195, 0.1765, 0.9174],\n",
      "         [0.0217, 0.7745, 0.5333,  ..., 0.8746, 0.8097, 0.3600],\n",
      "         ...,\n",
      "         [0.1289, 0.3125, 0.1091,  ..., 0.0795, 0.0127, 0.1263],\n",
      "         [0.2114, 0.5469, 0.0092,  ..., 0.2134, 0.9842, 0.5026],\n",
      "         [0.1928, 0.1241, 0.0061,  ..., 0.0270, 0.1637, 0.3071]]])\n",
      "tensor([[[5.3769, 5.3562, 3.6672,  ..., 4.0452, 4.6149, 4.8499],\n",
      "         [6.0176, 7.3629, 4.8545,  ..., 5.9350, 6.3229, 6.1488],\n",
      "         [5.4064, 5.0774, 3.3237,  ..., 4.3080, 4.8996, 4.8876],\n",
      "         ...,\n",
      "         [4.9644, 5.2897, 3.4967,  ..., 4.9785, 4.6524, 4.5766],\n",
      "         [4.6395, 6.2148, 4.5063,  ..., 4.4329, 5.1955, 5.1394],\n",
      "         [5.3677, 5.3647, 3.3443,  ..., 4.8872, 3.5763, 3.8792]],\n",
      "\n",
      "        [[5.7530, 5.1641, 5.3934,  ..., 5.3629, 5.9560, 6.2871],\n",
      "         [4.2398, 4.7590, 4.6417,  ..., 4.0587, 4.8985, 5.6467],\n",
      "         [4.6052, 5.3506, 6.1704,  ..., 6.1523, 6.1513, 6.4705],\n",
      "         ...,\n",
      "         [4.4861, 3.7961, 4.5442,  ..., 4.5287, 5.8160, 5.8806],\n",
      "         [5.2728, 5.6042, 6.1897,  ..., 5.4256, 6.6280, 6.8701],\n",
      "         [4.2793, 4.2989, 5.2264,  ..., 5.2703, 5.4371, 5.4325]],\n",
      "\n",
      "        [[5.1465, 4.9133, 4.6907,  ..., 5.4996, 5.6787, 6.0146],\n",
      "         [5.2888, 4.5154, 5.1753,  ..., 4.5159, 6.1884, 6.3613],\n",
      "         [4.7466, 4.6611, 4.9452,  ..., 4.5539, 5.7133, 6.1701],\n",
      "         ...,\n",
      "         [5.0981, 4.7414, 5.1271,  ..., 4.4190, 6.3322, 6.6939],\n",
      "         [4.0710, 4.1183, 4.1706,  ..., 4.0205, 4.5032, 4.9148],\n",
      "         [5.0452, 4.9593, 5.1179,  ..., 4.9472, 6.3618, 6.5464]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.7811, 4.0019, 3.2041,  ..., 3.5504, 3.6970, 4.7838],\n",
      "         [4.3495, 5.4072, 4.3550,  ..., 3.4719, 3.5358, 4.8074],\n",
      "         [4.5278, 5.2631, 3.9349,  ..., 4.1654, 3.2167, 4.8782],\n",
      "         ...,\n",
      "         [6.5272, 7.8672, 5.8494,  ..., 4.0980, 5.0484, 5.9586],\n",
      "         [5.2436, 6.5378, 4.6179,  ..., 3.6009, 3.7794, 4.8654],\n",
      "         [5.0834, 6.1662, 4.2760,  ..., 3.7959, 3.6507, 4.2293]],\n",
      "\n",
      "        [[5.3015, 7.0149, 4.5224,  ..., 7.0750, 6.1723, 5.8548],\n",
      "         [4.6878, 5.7594, 3.6460,  ..., 5.3142, 5.3235, 4.1250],\n",
      "         [4.8913, 5.0651, 4.0582,  ..., 5.0322, 4.2083, 3.6239],\n",
      "         ...,\n",
      "         [5.7341, 6.9169, 4.6026,  ..., 6.8262, 6.2857, 5.1432],\n",
      "         [4.1367, 5.2632, 3.4299,  ..., 5.8860, 4.3537, 3.8766],\n",
      "         [4.1082, 4.6837, 3.6298,  ..., 4.6081, 4.3666, 3.2335]],\n",
      "\n",
      "        [[4.5287, 4.8539, 4.8305,  ..., 4.3182, 5.0383, 4.5920],\n",
      "         [5.3175, 5.1111, 5.1389,  ..., 5.3720, 5.4802, 5.2101],\n",
      "         [5.8162, 6.6956, 6.6658,  ..., 7.2966, 6.3936, 6.7250],\n",
      "         ...,\n",
      "         [4.3764, 4.3506, 4.7538,  ..., 5.0467, 4.7294, 4.4546],\n",
      "         [4.9926, 4.3769, 5.4274,  ..., 5.2647, 4.7450, 5.2782],\n",
      "         [3.4340, 4.1574, 4.4316,  ..., 4.6406, 4.8414, 4.8216]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------\")\n",
    "# Batch Matrix Multiplication\n",
    "batch = 32\n",
    "n=10\n",
    "m=20\n",
    "p=30\n",
    "\n",
    "tensor1 = torch.rand((batch,n,m))\n",
    "print(tensor1)\n",
    "tensor2 = torch.rand((batch,m,p))\n",
    "print(tensor2)\n",
    "out_bmm = torch.bmm(tensor1,tensor2) #(batch,n,p)\n",
    "print(out_bmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d50af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4592, 0.5419, 0.9555, 0.1624, 0.8424],\n",
      "        [0.9012, 0.6013, 0.0572, 0.5856, 0.8550],\n",
      "        [0.0559, 0.2908, 0.8955, 0.9250, 0.3951],\n",
      "        [0.8237, 0.7366, 0.4791, 0.2407, 0.5614],\n",
      "        [0.1636, 0.6426, 0.7882, 0.4569, 0.6149]])\n",
      "tensor([[0.8071, 0.2254, 0.8650, 0.0590, 0.5116]])\n",
      "tensor([[-0.3478,  0.3165,  0.0904,  0.1034,  0.3308],\n",
      "        [ 0.0941,  0.3758, -0.8078,  0.5265,  0.3435],\n",
      "        [-0.7511,  0.0654,  0.0305,  0.8660, -0.1165],\n",
      "        [ 0.0167,  0.5111, -0.3859,  0.1817,  0.0499],\n",
      "        [-0.6435,  0.4171, -0.0768,  0.3979,  0.1034]])\n",
      "tensor([[0.5336, 0.8710, 0.9613, 0.8983, 0.9160],\n",
      "        [0.9194, 0.8916, 0.0842, 0.9689, 0.9230],\n",
      "        [0.0975, 0.7570, 0.9090, 0.9954, 0.6218],\n",
      "        [0.8551, 0.9334, 0.5292, 0.9194, 0.7443],\n",
      "        [0.2320, 0.9051, 0.8139, 0.9548, 0.7798]])\n"
     ]
    }
   ],
   "source": [
    "#Examble of Broadcasting\n",
    "x1=torch.rand((5,5))\n",
    "x2=torch.rand((1,5))\n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "\n",
    "x3=x1-x2\n",
    "print(x3)\n",
    "x4=x1 ** x2\n",
    "print(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be864817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(142)\n",
      "tensor(100)\n",
      "tensor(0)\n",
      "tensor(12)\n",
      "tensor(1)\n",
      "tensor([100,  12,  30])\n",
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor([False, False, False])\n",
      "tensor([7, 8, 9])\n",
      "tensor([2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# other useful tensor operations\n",
    "x = torch.tensor([100,12,30])\n",
    "y=torch.tensor([9,8,7])\n",
    "\n",
    "sum_x = torch.sum(x, dim=0)\n",
    "print(sum_x)\n",
    "\n",
    "values,indicates =torch.max(x,dim=0)\n",
    "print(values)\n",
    "print(indicates)\n",
    "\n",
    "values,indicates =torch.min(x,dim=0)\n",
    "print(values)\n",
    "print(indicates)\n",
    "\n",
    "abs_x = torch.abs(x)\n",
    "print(abs_x)\n",
    "\n",
    "z = torch.argmax(x, dim=0)\n",
    "z1 = torch.argmin(x, dim=0)\n",
    "print(z)\n",
    "print(z1)\n",
    "\n",
    "mean_x = torch.mean(x.float(), dim=0)\n",
    "z = torch.eq(x,y)\n",
    "print(z)\n",
    "\n",
    "sorted_y, indices = torch.sort(y, dim=0, descending=False)\n",
    "print(sorted_y)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0d28710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 1, 1])\n",
      "tensor(True)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "z= torch.clamp(x,min=0)\n",
    "print(z)\n",
    "x=torch.tensor([1,0,1,1,1], dtype=torch.bool)\n",
    "z1=torch.any(x)\n",
    "z2=torch.all(x)\n",
    "\n",
    "print(z1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8cafa66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n",
      "tensor([0.4391, 0.9678, 0.6426, 0.4236, 0.9825, 0.9355, 0.7972, 0.3196, 0.6735,\n",
      "        0.5864])\n",
      "tensor([0.6426, 0.7870, 0.8218, 0.4196, 0.9885, 0.2740, 0.1319, 0.5043, 0.0621,\n",
      "        0.0887])\n"
     ]
    }
   ],
   "source": [
    "##Tensor Indexing\n",
    "batch_size = 10\n",
    "features = 25\n",
    "x = torch.rand((batch_size, features))\n",
    "\n",
    "print(x[0].shape) #x[0,:]\n",
    "print(x[:,0])\n",
    "print(x[2,0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "81f1fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 8])\n",
      "tensor([[0.3691, 0.1706, 0.0649, 0.1515, 0.1876],\n",
      "        [0.9741, 0.9906, 0.2242, 0.9740, 0.0461],\n",
      "        [0.8948, 0.1059, 0.9822, 0.6974, 0.0741]])\n",
      "tensor([1, 0])\n",
      "tensor([4, 0])\n",
      "tensor([0.0461, 0.3691])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#fancy indexing\n",
    "x= torch.arange(10)\n",
    "indices = [2,5,8]\n",
    "print(x[indices])\n",
    "\n",
    "x=torch.rand((3,5))\n",
    "print(x)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c02dea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 9])\n",
      "tensor([0, 1])\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# More Advance Indexing\n",
    "x = torch.arange(10)\n",
    "print(x[(x<2) | (x>8)])\n",
    "print(x[(x<2) & (x<8)])\n",
    "print(x[x.remainder(2)==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0d5c0b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#useful operations\n",
    "x = torch.arange(10)\n",
    "print(torch.where(x>5,x,x*2)) #if?y:N\n",
    "print(torch.tensor([0,0,1,2,2,3,4]).unique())\n",
    "print(x.ndimension())\n",
    "print(x.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d30f215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 3, 6],\n",
      "        [1, 4, 7],\n",
      "        [2, 5, 8]])\n",
      "tensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\n",
      "torch.Size([4, 5])\n",
      "torch.Size([2, 10])\n",
      "torch.Size([10])\n",
      "tensor([[[4.9820e-01, 2.5019e-02, 6.6935e-01, 2.9870e-01, 8.0325e-01],\n",
      "         [3.2394e-01, 3.1330e-01, 4.6409e-01, 7.8112e-02, 8.5268e-01]],\n",
      "\n",
      "        [[5.4993e-01, 9.7688e-01, 6.6193e-01, 1.8739e-01, 1.0301e-01],\n",
      "         [9.7193e-03, 4.1621e-01, 9.3563e-01, 4.0887e-01, 2.5019e-01]],\n",
      "\n",
      "        [[5.9586e-01, 9.2797e-01, 3.4732e-01, 4.8150e-01, 8.3081e-02],\n",
      "         [5.7524e-01, 7.1256e-01, 3.1708e-01, 2.1021e-01, 8.9526e-01]],\n",
      "\n",
      "        [[4.0935e-01, 9.6987e-01, 7.4208e-01, 4.8812e-01, 9.3496e-01],\n",
      "         [5.5971e-01, 2.6323e-01, 8.3704e-01, 2.3095e-01, 7.5276e-01]],\n",
      "\n",
      "        [[4.7402e-01, 4.4666e-01, 4.8541e-01, 9.6193e-01, 6.7902e-01],\n",
      "         [3.3606e-01, 4.4141e-01, 5.3456e-01, 8.4278e-01, 3.1317e-01]],\n",
      "\n",
      "        [[4.8341e-01, 6.1801e-02, 7.5289e-01, 1.7276e-02, 3.9201e-01],\n",
      "         [4.9839e-01, 2.2807e-01, 6.8118e-01, 6.6458e-01, 6.8077e-01]],\n",
      "\n",
      "        [[5.2084e-01, 2.6699e-02, 3.9660e-01, 1.4862e-01, 3.1357e-01],\n",
      "         [3.3496e-01, 2.3301e-01, 2.1425e-01, 5.9948e-01, 9.5972e-01]],\n",
      "\n",
      "        [[7.6650e-01, 4.5880e-01, 6.8276e-01, 6.8145e-02, 8.2979e-02],\n",
      "         [7.1871e-01, 5.3278e-02, 1.5230e-01, 5.1501e-01, 8.2937e-01]],\n",
      "\n",
      "        [[2.5302e-02, 8.4855e-01, 6.1168e-01, 6.0427e-01, 4.6792e-01],\n",
      "         [4.7976e-01, 7.3957e-03, 4.5936e-01, 7.7953e-01, 2.9382e-01]],\n",
      "\n",
      "        [[1.8732e-01, 8.3019e-01, 4.0053e-02, 4.5753e-01, 9.4098e-01],\n",
      "         [1.1641e-01, 9.4152e-02, 7.7207e-01, 2.5222e-01, 3.2881e-01]],\n",
      "\n",
      "        [[5.2664e-01, 8.6410e-01, 2.9300e-01, 4.6305e-01, 8.6804e-01],\n",
      "         [5.3053e-01, 2.3750e-01, 5.6302e-01, 3.9295e-01, 8.6157e-01]],\n",
      "\n",
      "        [[9.8850e-01, 2.1853e-01, 4.8979e-01, 6.5416e-01, 5.2797e-01],\n",
      "         [7.8690e-01, 7.2991e-01, 4.3244e-01, 4.6027e-01, 1.9639e-01]],\n",
      "\n",
      "        [[1.9374e-01, 8.8780e-01, 1.6686e-01, 3.9685e-01, 8.5031e-01],\n",
      "         [3.2214e-01, 8.9324e-01, 5.8656e-01, 4.8841e-01, 6.4447e-01]],\n",
      "\n",
      "        [[2.1593e-01, 5.8947e-01, 4.1472e-01, 1.0733e-01, 3.7793e-01],\n",
      "         [5.3669e-02, 7.3369e-01, 8.2589e-01, 8.3968e-02, 3.3667e-01]],\n",
      "\n",
      "        [[1.5617e-01, 2.3857e-01, 9.3800e-02, 6.9014e-01, 8.9923e-01],\n",
      "         [2.1652e-01, 3.9893e-01, 5.7586e-01, 2.9442e-01, 6.3430e-01]],\n",
      "\n",
      "        [[1.4627e-01, 8.9348e-01, 5.6231e-01, 7.6472e-01, 8.4121e-01],\n",
      "         [3.6812e-01, 5.1520e-01, 6.1097e-01, 5.0246e-01, 7.5816e-01]],\n",
      "\n",
      "        [[5.9198e-01, 3.3871e-01, 3.3662e-01, 4.4135e-01, 3.9127e-02],\n",
      "         [4.3168e-01, 4.2635e-01, 8.1531e-02, 6.5798e-01, 3.1808e-01]],\n",
      "\n",
      "        [[6.7436e-01, 6.5906e-01, 8.9211e-01, 8.9465e-01, 8.0722e-01],\n",
      "         [6.6154e-01, 2.0375e-01, 4.1548e-01, 7.2563e-01, 3.7792e-01]],\n",
      "\n",
      "        [[7.6982e-01, 9.4911e-01, 3.7540e-01, 9.3252e-01, 5.1134e-01],\n",
      "         [9.6054e-01, 4.8690e-01, 5.7112e-01, 4.1850e-01, 4.8402e-01]],\n",
      "\n",
      "        [[4.0051e-01, 2.8696e-01, 4.2898e-01, 8.4862e-01, 6.2695e-01],\n",
      "         [1.8334e-01, 2.5785e-01, 5.3242e-01, 5.8991e-01, 1.5162e-01]],\n",
      "\n",
      "        [[1.0507e-01, 7.3966e-01, 7.0756e-01, 7.3558e-01, 8.8680e-01],\n",
      "         [3.1282e-01, 6.2778e-01, 8.2679e-01, 1.6431e-01, 9.5494e-01]],\n",
      "\n",
      "        [[8.4192e-01, 8.0141e-01, 3.8017e-01, 1.4139e-01, 6.2342e-01],\n",
      "         [9.3898e-01, 9.8914e-01, 4.1875e-01, 5.2768e-01, 7.2474e-01]],\n",
      "\n",
      "        [[1.0981e-01, 8.2297e-01, 9.9739e-02, 3.2845e-01, 2.3236e-01],\n",
      "         [6.2623e-01, 5.3916e-01, 5.1957e-01, 7.2197e-01, 2.5653e-01]],\n",
      "\n",
      "        [[1.6667e-01, 6.8897e-01, 6.4344e-01, 7.6278e-03, 8.1833e-01],\n",
      "         [4.2144e-01, 2.8836e-01, 9.4484e-01, 4.1412e-01, 6.2051e-01]],\n",
      "\n",
      "        [[4.5749e-01, 6.5351e-01, 6.9356e-01, 2.5241e-01, 2.4187e-01],\n",
      "         [1.3435e-01, 6.6576e-01, 4.9174e-01, 4.5058e-01, 4.0943e-01]],\n",
      "\n",
      "        [[6.7608e-01, 1.2489e-01, 1.6025e-01, 4.6052e-01, 5.5831e-01],\n",
      "         [3.0066e-01, 7.4594e-01, 9.0220e-01, 5.8204e-02, 1.9139e-01]],\n",
      "\n",
      "        [[9.7083e-01, 5.0385e-01, 3.9432e-01, 7.0627e-01, 7.4570e-01],\n",
      "         [9.7389e-01, 2.1162e-01, 1.7810e-01, 8.0912e-01, 5.2930e-01]],\n",
      "\n",
      "        [[5.3379e-01, 1.6881e-01, 3.2749e-01, 6.2745e-01, 3.4034e-01],\n",
      "         [2.6473e-01, 9.7646e-01, 8.4946e-01, 8.8943e-01, 7.6572e-01]],\n",
      "\n",
      "        [[2.4764e-01, 7.7617e-01, 7.8181e-01, 9.1844e-01, 5.5204e-02],\n",
      "         [8.3684e-01, 5.1398e-01, 7.2979e-01, 3.1489e-01, 5.2788e-01]],\n",
      "\n",
      "        [[3.6573e-01, 8.3101e-01, 2.4489e-01, 2.2751e-01, 3.1247e-01],\n",
      "         [5.5166e-02, 1.8292e-01, 6.0070e-01, 4.0785e-01, 9.5525e-01]],\n",
      "\n",
      "        [[2.9918e-01, 4.1627e-01, 5.4299e-01, 9.4373e-01, 2.3764e-01],\n",
      "         [6.9364e-01, 8.9916e-02, 4.1899e-01, 2.1765e-01, 8.6373e-01]],\n",
      "\n",
      "        [[4.2318e-01, 5.8058e-02, 3.8549e-01, 3.5584e-01, 1.7479e-02],\n",
      "         [7.9991e-01, 2.0574e-01, 3.0747e-01, 3.3894e-01, 8.0180e-01]],\n",
      "\n",
      "        [[3.3421e-01, 1.5795e-01, 6.6771e-01, 1.9163e-01, 8.0352e-01],\n",
      "         [6.2053e-01, 9.1321e-01, 3.0908e-01, 7.8440e-01, 5.5830e-01]],\n",
      "\n",
      "        [[9.1796e-01, 1.4501e-01, 7.5259e-01, 4.0987e-01, 3.7271e-01],\n",
      "         [4.8242e-01, 6.0856e-01, 5.3648e-02, 7.3008e-01, 8.2057e-01]],\n",
      "\n",
      "        [[2.9892e-01, 4.6094e-01, 2.3558e-01, 5.2384e-01, 4.4152e-01],\n",
      "         [6.6108e-01, 2.9865e-01, 7.7854e-01, 4.8939e-01, 2.2102e-02]],\n",
      "\n",
      "        [[9.4437e-01, 1.2713e-01, 2.5117e-01, 7.6138e-02, 6.7463e-01],\n",
      "         [6.1730e-02, 8.9791e-01, 3.2598e-02, 8.7585e-01, 7.4694e-01]],\n",
      "\n",
      "        [[5.6875e-01, 9.4412e-01, 9.9037e-01, 1.8017e-01, 1.4909e-01],\n",
      "         [4.2267e-01, 9.4085e-01, 8.5766e-01, 1.1183e-01, 5.7323e-02]],\n",
      "\n",
      "        [[9.6646e-01, 9.2699e-01, 9.6217e-01, 7.5272e-01, 5.8849e-01],\n",
      "         [6.7572e-01, 7.7158e-01, 4.9657e-01, 7.3700e-01, 6.3742e-01]],\n",
      "\n",
      "        [[1.9154e-01, 6.3937e-01, 7.7031e-01, 4.7276e-01, 3.7827e-01],\n",
      "         [4.1095e-01, 7.8159e-01, 3.1208e-01, 2.7266e-01, 1.4946e-01]],\n",
      "\n",
      "        [[2.8640e-01, 1.9827e-01, 5.4780e-02, 1.7045e-01, 2.9130e-01],\n",
      "         [8.9085e-01, 3.9935e-01, 4.6931e-01, 7.5877e-01, 6.3065e-02]],\n",
      "\n",
      "        [[6.6377e-02, 6.0991e-01, 9.2871e-01, 9.7988e-01, 7.9527e-01],\n",
      "         [1.8670e-01, 6.7698e-01, 3.6699e-01, 9.0674e-01, 8.5329e-01]],\n",
      "\n",
      "        [[4.2721e-01, 1.2227e-01, 7.1370e-01, 3.1394e-01, 5.3658e-01],\n",
      "         [3.0617e-01, 1.7674e-01, 8.3272e-01, 8.7956e-01, 6.5030e-01]],\n",
      "\n",
      "        [[5.8986e-01, 9.4534e-01, 8.8037e-01, 4.9842e-01, 8.7965e-01],\n",
      "         [9.4364e-01, 2.6794e-01, 5.3046e-01, 1.2759e-01, 8.8854e-01]],\n",
      "\n",
      "        [[9.3768e-01, 1.2092e-01, 4.7919e-01, 2.2307e-02, 8.1709e-03],\n",
      "         [4.9227e-02, 5.8114e-02, 4.8559e-01, 3.7521e-01, 6.0703e-01]],\n",
      "\n",
      "        [[5.6694e-01, 9.9923e-02, 3.4414e-01, 9.2158e-01, 2.6480e-01],\n",
      "         [1.9897e-01, 6.2860e-02, 6.7697e-01, 4.4283e-01, 7.9770e-01]],\n",
      "\n",
      "        [[7.6686e-01, 8.2016e-01, 2.8726e-02, 7.6360e-01, 6.7340e-01],\n",
      "         [2.1031e-01, 2.9016e-01, 5.8910e-01, 9.9619e-01, 2.6083e-01]],\n",
      "\n",
      "        [[1.8759e-01, 8.6798e-02, 7.1196e-01, 9.4313e-01, 8.0083e-01],\n",
      "         [2.8181e-01, 4.4143e-01, 8.1968e-01, 4.5364e-01, 7.8148e-01]],\n",
      "\n",
      "        [[1.7128e-01, 8.6320e-01, 9.6506e-01, 6.4995e-01, 4.8806e-02],\n",
      "         [3.7751e-02, 1.6327e-02, 2.9761e-02, 3.8495e-01, 3.7441e-01]],\n",
      "\n",
      "        [[1.2759e-01, 3.3959e-02, 2.8937e-01, 1.8862e-01, 1.9537e-01],\n",
      "         [5.6349e-01, 8.7373e-01, 6.5357e-01, 7.5873e-01, 8.7522e-01]],\n",
      "\n",
      "        [[6.8102e-01, 4.7009e-01, 5.0652e-01, 1.3396e-01, 2.1806e-01],\n",
      "         [9.2666e-01, 9.3982e-01, 8.7395e-01, 2.6643e-01, 2.2491e-01]],\n",
      "\n",
      "        [[5.3043e-01, 2.0499e-01, 9.0912e-01, 1.6566e-01, 5.5044e-01],\n",
      "         [3.6372e-01, 7.1204e-01, 2.9042e-02, 3.3993e-01, 8.6470e-01]],\n",
      "\n",
      "        [[1.2500e-01, 6.5139e-02, 9.9311e-01, 3.1042e-01, 5.1778e-01],\n",
      "         [5.1364e-01, 5.4727e-01, 3.4430e-01, 1.8885e-01, 7.2184e-01]],\n",
      "\n",
      "        [[3.5303e-02, 2.4965e-01, 4.4406e-01, 4.1388e-01, 6.0647e-01],\n",
      "         [5.9158e-02, 9.6758e-01, 6.2901e-01, 6.0162e-01, 9.0888e-01]],\n",
      "\n",
      "        [[2.6552e-01, 2.8656e-01, 8.6937e-01, 6.7855e-01, 5.8842e-01],\n",
      "         [5.4454e-01, 9.3954e-01, 6.7839e-01, 3.4200e-01, 4.2288e-01]],\n",
      "\n",
      "        [[8.8701e-01, 6.0910e-01, 1.5379e-01, 6.4186e-02, 9.2614e-01],\n",
      "         [6.5957e-01, 9.7558e-01, 5.7014e-02, 3.9446e-01, 2.8716e-02]],\n",
      "\n",
      "        [[4.5210e-01, 1.4567e-01, 2.5333e-01, 9.7752e-04, 2.6472e-02],\n",
      "         [1.3695e-01, 7.9033e-01, 3.2448e-01, 9.1097e-01, 7.1448e-01]],\n",
      "\n",
      "        [[5.5277e-01, 9.9785e-02, 9.5815e-01, 5.6403e-02, 9.7337e-02],\n",
      "         [7.9048e-01, 4.7288e-02, 2.2486e-01, 2.1994e-01, 6.8016e-02]],\n",
      "\n",
      "        [[3.2819e-01, 8.5140e-01, 9.5320e-01, 4.4204e-01, 5.4745e-01],\n",
      "         [9.1508e-01, 1.3732e-01, 8.5408e-01, 2.5820e-01, 4.4454e-01]],\n",
      "\n",
      "        [[6.3017e-01, 2.6567e-01, 3.4844e-01, 2.6026e-01, 1.0832e-01],\n",
      "         [7.8677e-01, 5.9785e-01, 2.8243e-02, 8.0458e-01, 9.6208e-01]],\n",
      "\n",
      "        [[6.5500e-01, 5.8932e-01, 5.5649e-01, 6.8469e-02, 9.4978e-01],\n",
      "         [3.1398e-01, 1.4678e-01, 7.8384e-01, 9.1115e-01, 3.9552e-01]],\n",
      "\n",
      "        [[4.2877e-01, 2.9640e-01, 9.8522e-01, 2.3132e-01, 9.0997e-01],\n",
      "         [8.1559e-02, 5.3458e-01, 4.0584e-01, 9.3247e-01, 8.1839e-01]],\n",
      "\n",
      "        [[5.4363e-01, 8.5228e-01, 4.7013e-01, 5.8175e-02, 6.9026e-01],\n",
      "         [2.4952e-01, 6.0373e-02, 9.7353e-01, 2.4046e-02, 6.6149e-01]],\n",
      "\n",
      "        [[4.3709e-01, 7.6948e-01, 6.6225e-01, 8.8768e-01, 5.2279e-01],\n",
      "         [5.5095e-01, 6.3065e-01, 7.0336e-01, 1.2453e-01, 1.9548e-02]],\n",
      "\n",
      "        [[2.9477e-01, 8.5206e-02, 1.4141e-01, 7.3098e-01, 9.4078e-01],\n",
      "         [2.5605e-01, 8.7249e-01, 6.4450e-01, 4.1942e-01, 2.7241e-01]]])\n",
      "--------------------\n",
      "tensor([[4.9820e-01, 2.5019e-02, 6.6935e-01, 2.9870e-01, 8.0325e-01, 3.2394e-01,\n",
      "         3.1330e-01, 4.6409e-01, 7.8112e-02, 8.5268e-01],\n",
      "        [5.4993e-01, 9.7688e-01, 6.6193e-01, 1.8739e-01, 1.0301e-01, 9.7193e-03,\n",
      "         4.1621e-01, 9.3563e-01, 4.0887e-01, 2.5019e-01],\n",
      "        [5.9586e-01, 9.2797e-01, 3.4732e-01, 4.8150e-01, 8.3081e-02, 5.7524e-01,\n",
      "         7.1256e-01, 3.1708e-01, 2.1021e-01, 8.9526e-01],\n",
      "        [4.0935e-01, 9.6987e-01, 7.4208e-01, 4.8812e-01, 9.3496e-01, 5.5971e-01,\n",
      "         2.6323e-01, 8.3704e-01, 2.3095e-01, 7.5276e-01],\n",
      "        [4.7402e-01, 4.4666e-01, 4.8541e-01, 9.6193e-01, 6.7902e-01, 3.3606e-01,\n",
      "         4.4141e-01, 5.3456e-01, 8.4278e-01, 3.1317e-01],\n",
      "        [4.8341e-01, 6.1801e-02, 7.5289e-01, 1.7276e-02, 3.9201e-01, 4.9839e-01,\n",
      "         2.2807e-01, 6.8118e-01, 6.6458e-01, 6.8077e-01],\n",
      "        [5.2084e-01, 2.6699e-02, 3.9660e-01, 1.4862e-01, 3.1357e-01, 3.3496e-01,\n",
      "         2.3301e-01, 2.1425e-01, 5.9948e-01, 9.5972e-01],\n",
      "        [7.6650e-01, 4.5880e-01, 6.8276e-01, 6.8145e-02, 8.2979e-02, 7.1871e-01,\n",
      "         5.3278e-02, 1.5230e-01, 5.1501e-01, 8.2937e-01],\n",
      "        [2.5302e-02, 8.4855e-01, 6.1168e-01, 6.0427e-01, 4.6792e-01, 4.7976e-01,\n",
      "         7.3957e-03, 4.5936e-01, 7.7953e-01, 2.9382e-01],\n",
      "        [1.8732e-01, 8.3019e-01, 4.0053e-02, 4.5753e-01, 9.4098e-01, 1.1641e-01,\n",
      "         9.4152e-02, 7.7207e-01, 2.5222e-01, 3.2881e-01],\n",
      "        [5.2664e-01, 8.6410e-01, 2.9300e-01, 4.6305e-01, 8.6804e-01, 5.3053e-01,\n",
      "         2.3750e-01, 5.6302e-01, 3.9295e-01, 8.6157e-01],\n",
      "        [9.8850e-01, 2.1853e-01, 4.8979e-01, 6.5416e-01, 5.2797e-01, 7.8690e-01,\n",
      "         7.2991e-01, 4.3244e-01, 4.6027e-01, 1.9639e-01],\n",
      "        [1.9374e-01, 8.8780e-01, 1.6686e-01, 3.9685e-01, 8.5031e-01, 3.2214e-01,\n",
      "         8.9324e-01, 5.8656e-01, 4.8841e-01, 6.4447e-01],\n",
      "        [2.1593e-01, 5.8947e-01, 4.1472e-01, 1.0733e-01, 3.7793e-01, 5.3669e-02,\n",
      "         7.3369e-01, 8.2589e-01, 8.3968e-02, 3.3667e-01],\n",
      "        [1.5617e-01, 2.3857e-01, 9.3800e-02, 6.9014e-01, 8.9923e-01, 2.1652e-01,\n",
      "         3.9893e-01, 5.7586e-01, 2.9442e-01, 6.3430e-01],\n",
      "        [1.4627e-01, 8.9348e-01, 5.6231e-01, 7.6472e-01, 8.4121e-01, 3.6812e-01,\n",
      "         5.1520e-01, 6.1097e-01, 5.0246e-01, 7.5816e-01],\n",
      "        [5.9198e-01, 3.3871e-01, 3.3662e-01, 4.4135e-01, 3.9127e-02, 4.3168e-01,\n",
      "         4.2635e-01, 8.1531e-02, 6.5798e-01, 3.1808e-01],\n",
      "        [6.7436e-01, 6.5906e-01, 8.9211e-01, 8.9465e-01, 8.0722e-01, 6.6154e-01,\n",
      "         2.0375e-01, 4.1548e-01, 7.2563e-01, 3.7792e-01],\n",
      "        [7.6982e-01, 9.4911e-01, 3.7540e-01, 9.3252e-01, 5.1134e-01, 9.6054e-01,\n",
      "         4.8690e-01, 5.7112e-01, 4.1850e-01, 4.8402e-01],\n",
      "        [4.0051e-01, 2.8696e-01, 4.2898e-01, 8.4862e-01, 6.2695e-01, 1.8334e-01,\n",
      "         2.5785e-01, 5.3242e-01, 5.8991e-01, 1.5162e-01],\n",
      "        [1.0507e-01, 7.3966e-01, 7.0756e-01, 7.3558e-01, 8.8680e-01, 3.1282e-01,\n",
      "         6.2778e-01, 8.2679e-01, 1.6431e-01, 9.5494e-01],\n",
      "        [8.4192e-01, 8.0141e-01, 3.8017e-01, 1.4139e-01, 6.2342e-01, 9.3898e-01,\n",
      "         9.8914e-01, 4.1875e-01, 5.2768e-01, 7.2474e-01],\n",
      "        [1.0981e-01, 8.2297e-01, 9.9739e-02, 3.2845e-01, 2.3236e-01, 6.2623e-01,\n",
      "         5.3916e-01, 5.1957e-01, 7.2197e-01, 2.5653e-01],\n",
      "        [1.6667e-01, 6.8897e-01, 6.4344e-01, 7.6278e-03, 8.1833e-01, 4.2144e-01,\n",
      "         2.8836e-01, 9.4484e-01, 4.1412e-01, 6.2051e-01],\n",
      "        [4.5749e-01, 6.5351e-01, 6.9356e-01, 2.5241e-01, 2.4187e-01, 1.3435e-01,\n",
      "         6.6576e-01, 4.9174e-01, 4.5058e-01, 4.0943e-01],\n",
      "        [6.7608e-01, 1.2489e-01, 1.6025e-01, 4.6052e-01, 5.5831e-01, 3.0066e-01,\n",
      "         7.4594e-01, 9.0220e-01, 5.8204e-02, 1.9139e-01],\n",
      "        [9.7083e-01, 5.0385e-01, 3.9432e-01, 7.0627e-01, 7.4570e-01, 9.7389e-01,\n",
      "         2.1162e-01, 1.7810e-01, 8.0912e-01, 5.2930e-01],\n",
      "        [5.3379e-01, 1.6881e-01, 3.2749e-01, 6.2745e-01, 3.4034e-01, 2.6473e-01,\n",
      "         9.7646e-01, 8.4946e-01, 8.8943e-01, 7.6572e-01],\n",
      "        [2.4764e-01, 7.7617e-01, 7.8181e-01, 9.1844e-01, 5.5204e-02, 8.3684e-01,\n",
      "         5.1398e-01, 7.2979e-01, 3.1489e-01, 5.2788e-01],\n",
      "        [3.6573e-01, 8.3101e-01, 2.4489e-01, 2.2751e-01, 3.1247e-01, 5.5166e-02,\n",
      "         1.8292e-01, 6.0070e-01, 4.0785e-01, 9.5525e-01],\n",
      "        [2.9918e-01, 4.1627e-01, 5.4299e-01, 9.4373e-01, 2.3764e-01, 6.9364e-01,\n",
      "         8.9916e-02, 4.1899e-01, 2.1765e-01, 8.6373e-01],\n",
      "        [4.2318e-01, 5.8058e-02, 3.8549e-01, 3.5584e-01, 1.7479e-02, 7.9991e-01,\n",
      "         2.0574e-01, 3.0747e-01, 3.3894e-01, 8.0180e-01],\n",
      "        [3.3421e-01, 1.5795e-01, 6.6771e-01, 1.9163e-01, 8.0352e-01, 6.2053e-01,\n",
      "         9.1321e-01, 3.0908e-01, 7.8440e-01, 5.5830e-01],\n",
      "        [9.1796e-01, 1.4501e-01, 7.5259e-01, 4.0987e-01, 3.7271e-01, 4.8242e-01,\n",
      "         6.0856e-01, 5.3648e-02, 7.3008e-01, 8.2057e-01],\n",
      "        [2.9892e-01, 4.6094e-01, 2.3558e-01, 5.2384e-01, 4.4152e-01, 6.6108e-01,\n",
      "         2.9865e-01, 7.7854e-01, 4.8939e-01, 2.2102e-02],\n",
      "        [9.4437e-01, 1.2713e-01, 2.5117e-01, 7.6138e-02, 6.7463e-01, 6.1730e-02,\n",
      "         8.9791e-01, 3.2598e-02, 8.7585e-01, 7.4694e-01],\n",
      "        [5.6875e-01, 9.4412e-01, 9.9037e-01, 1.8017e-01, 1.4909e-01, 4.2267e-01,\n",
      "         9.4085e-01, 8.5766e-01, 1.1183e-01, 5.7323e-02],\n",
      "        [9.6646e-01, 9.2699e-01, 9.6217e-01, 7.5272e-01, 5.8849e-01, 6.7572e-01,\n",
      "         7.7158e-01, 4.9657e-01, 7.3700e-01, 6.3742e-01],\n",
      "        [1.9154e-01, 6.3937e-01, 7.7031e-01, 4.7276e-01, 3.7827e-01, 4.1095e-01,\n",
      "         7.8159e-01, 3.1208e-01, 2.7266e-01, 1.4946e-01],\n",
      "        [2.8640e-01, 1.9827e-01, 5.4780e-02, 1.7045e-01, 2.9130e-01, 8.9085e-01,\n",
      "         3.9935e-01, 4.6931e-01, 7.5877e-01, 6.3065e-02],\n",
      "        [6.6377e-02, 6.0991e-01, 9.2871e-01, 9.7988e-01, 7.9527e-01, 1.8670e-01,\n",
      "         6.7698e-01, 3.6699e-01, 9.0674e-01, 8.5329e-01],\n",
      "        [4.2721e-01, 1.2227e-01, 7.1370e-01, 3.1394e-01, 5.3658e-01, 3.0617e-01,\n",
      "         1.7674e-01, 8.3272e-01, 8.7956e-01, 6.5030e-01],\n",
      "        [5.8986e-01, 9.4534e-01, 8.8037e-01, 4.9842e-01, 8.7965e-01, 9.4364e-01,\n",
      "         2.6794e-01, 5.3046e-01, 1.2759e-01, 8.8854e-01],\n",
      "        [9.3768e-01, 1.2092e-01, 4.7919e-01, 2.2307e-02, 8.1709e-03, 4.9227e-02,\n",
      "         5.8114e-02, 4.8559e-01, 3.7521e-01, 6.0703e-01],\n",
      "        [5.6694e-01, 9.9923e-02, 3.4414e-01, 9.2158e-01, 2.6480e-01, 1.9897e-01,\n",
      "         6.2860e-02, 6.7697e-01, 4.4283e-01, 7.9770e-01],\n",
      "        [7.6686e-01, 8.2016e-01, 2.8726e-02, 7.6360e-01, 6.7340e-01, 2.1031e-01,\n",
      "         2.9016e-01, 5.8910e-01, 9.9619e-01, 2.6083e-01],\n",
      "        [1.8759e-01, 8.6798e-02, 7.1196e-01, 9.4313e-01, 8.0083e-01, 2.8181e-01,\n",
      "         4.4143e-01, 8.1968e-01, 4.5364e-01, 7.8148e-01],\n",
      "        [1.7128e-01, 8.6320e-01, 9.6506e-01, 6.4995e-01, 4.8806e-02, 3.7751e-02,\n",
      "         1.6327e-02, 2.9761e-02, 3.8495e-01, 3.7441e-01],\n",
      "        [1.2759e-01, 3.3959e-02, 2.8937e-01, 1.8862e-01, 1.9537e-01, 5.6349e-01,\n",
      "         8.7373e-01, 6.5357e-01, 7.5873e-01, 8.7522e-01],\n",
      "        [6.8102e-01, 4.7009e-01, 5.0652e-01, 1.3396e-01, 2.1806e-01, 9.2666e-01,\n",
      "         9.3982e-01, 8.7395e-01, 2.6643e-01, 2.2491e-01],\n",
      "        [5.3043e-01, 2.0499e-01, 9.0912e-01, 1.6566e-01, 5.5044e-01, 3.6372e-01,\n",
      "         7.1204e-01, 2.9042e-02, 3.3993e-01, 8.6470e-01],\n",
      "        [1.2500e-01, 6.5139e-02, 9.9311e-01, 3.1042e-01, 5.1778e-01, 5.1364e-01,\n",
      "         5.4727e-01, 3.4430e-01, 1.8885e-01, 7.2184e-01],\n",
      "        [3.5303e-02, 2.4965e-01, 4.4406e-01, 4.1388e-01, 6.0647e-01, 5.9158e-02,\n",
      "         9.6758e-01, 6.2901e-01, 6.0162e-01, 9.0888e-01],\n",
      "        [2.6552e-01, 2.8656e-01, 8.6937e-01, 6.7855e-01, 5.8842e-01, 5.4454e-01,\n",
      "         9.3954e-01, 6.7839e-01, 3.4200e-01, 4.2288e-01],\n",
      "        [8.8701e-01, 6.0910e-01, 1.5379e-01, 6.4186e-02, 9.2614e-01, 6.5957e-01,\n",
      "         9.7558e-01, 5.7014e-02, 3.9446e-01, 2.8716e-02],\n",
      "        [4.5210e-01, 1.4567e-01, 2.5333e-01, 9.7752e-04, 2.6472e-02, 1.3695e-01,\n",
      "         7.9033e-01, 3.2448e-01, 9.1097e-01, 7.1448e-01],\n",
      "        [5.5277e-01, 9.9785e-02, 9.5815e-01, 5.6403e-02, 9.7337e-02, 7.9048e-01,\n",
      "         4.7288e-02, 2.2486e-01, 2.1994e-01, 6.8016e-02],\n",
      "        [3.2819e-01, 8.5140e-01, 9.5320e-01, 4.4204e-01, 5.4745e-01, 9.1508e-01,\n",
      "         1.3732e-01, 8.5408e-01, 2.5820e-01, 4.4454e-01],\n",
      "        [6.3017e-01, 2.6567e-01, 3.4844e-01, 2.6026e-01, 1.0832e-01, 7.8677e-01,\n",
      "         5.9785e-01, 2.8243e-02, 8.0458e-01, 9.6208e-01],\n",
      "        [6.5500e-01, 5.8932e-01, 5.5649e-01, 6.8469e-02, 9.4978e-01, 3.1398e-01,\n",
      "         1.4678e-01, 7.8384e-01, 9.1115e-01, 3.9552e-01],\n",
      "        [4.2877e-01, 2.9640e-01, 9.8522e-01, 2.3132e-01, 9.0997e-01, 8.1559e-02,\n",
      "         5.3458e-01, 4.0584e-01, 9.3247e-01, 8.1839e-01],\n",
      "        [5.4363e-01, 8.5228e-01, 4.7013e-01, 5.8175e-02, 6.9026e-01, 2.4952e-01,\n",
      "         6.0373e-02, 9.7353e-01, 2.4046e-02, 6.6149e-01],\n",
      "        [4.3709e-01, 7.6948e-01, 6.6225e-01, 8.8768e-01, 5.2279e-01, 5.5095e-01,\n",
      "         6.3065e-01, 7.0336e-01, 1.2453e-01, 1.9548e-02],\n",
      "        [2.9477e-01, 8.5206e-02, 1.4141e-01, 7.3098e-01, 9.4078e-01, 2.5605e-01,\n",
      "         8.7249e-01, 6.4450e-01, 4.1942e-01, 2.7241e-01]])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "#reshaping\n",
    "x=torch.arange(9)\n",
    "x_3x3 = x.view(3,3) #allocate memory\n",
    "y_3x3 = x.reshape(3,3)  #save memory\n",
    "print(x_3x3)\n",
    "print(y_3x3)\n",
    "\n",
    "y=x_3x3.t() #row to colom swap\n",
    "print(y)\n",
    "print(y.contiguous().view(9))   #make it single vector\n",
    "\n",
    "x1=torch.rand((2,5))\n",
    "x2=torch.rand((2,5))\n",
    "\n",
    "print(torch.cat((x1,x2), dim=0).shape)\n",
    "print(torch.cat((x1,x2), dim=1).shape)\n",
    "\n",
    "z=x1.view(-1)\n",
    "print(z.shape)\n",
    "\n",
    "batch=64\n",
    "x = torch.rand((batch,2,5))\n",
    "print(x)\n",
    "print(\"--------------------\")\n",
    "z = x.view(batch,-1)\n",
    "print(z)\n",
    "print(z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "96510dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((100,2,5))\n",
    "z=x.permute(0,2,1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x.unsqueeze(0).shape)\n",
    "print(x.unsqueeze(1).shape)\n",
    "x=torch.arange(10).unsqueeze(0).unsqueeze(1) #1x1x10\n",
    "\n",
    "z=x.squeeze(0)\n",
    "print(z.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
